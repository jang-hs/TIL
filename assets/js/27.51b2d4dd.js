(window.webpackJsonp=window.webpackJsonp||[]).push([[27],{339:function(t,a,s){"use strict";s.r(a);var n=s(27),e=Object(n.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"sparksession과-sparkcontext-이해하기"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sparksession과-sparkcontext-이해하기"}},[t._v("#")]),t._v(" SparkSession과 SparkContext 이해하기")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://medium.com/@santosh_beora/understanding-sparksession-and-sparkcontext-in-pyspark-e74ecc688886",target:"_blank",rel:"noopener noreferrer"}},[t._v("Understanding SparkSession and SparkContext in PySpark"),a("OutboundLink")],1),t._v("를 읽고 정리하였습니다.")]),t._v(" "),a("p",[t._v("PySpark는 대규모 데이터 세트를 처리하기 위한 강력한 도구입니다. PySpark의 핵심 개념 중 두 가지는 "),a("code",[t._v("SparkSession")]),t._v("과 "),a("code",[t._v("SparkContext")]),t._v("입니다. 이를 간단하게 설명하고 몇 가지 예제를 통해 작동 방식을 살펴보겠습니다.")]),t._v(" "),a("h2",{attrs:{id:"sparksession이란"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sparksession이란"}},[t._v("#")]),t._v(" SparkSession이란?")]),t._v(" "),a("p",[a("code",[t._v("SparkSession")]),t._v("은 Spark 프로그래밍의 진입점입니다. Spark의 기능을 활용하고 DataFrame 및 DataSet을 생성할 수 있는 단일 진입점을 제공합니다.")]),t._v(" "),a("h2",{attrs:{id:"왜-sparksession을-사용할까요"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#왜-sparksession을-사용할까요"}},[t._v("#")]),t._v(" 왜 SparkSession을 사용할까요?")]),t._v(" "),a("ol",[a("li",[t._v("통합 인터페이스: 기존의 "),a("code",[t._v("SQLContext")]),t._v(", "),a("code",[t._v("HiveContext")]),t._v(", "),a("code",[t._v("SparkContext")]),t._v("를 단일 진입점으로 통합합니다.")]),t._v(" "),a("li",[t._v("사용 용이성: Spark 애플리케이션을 시작하고 구성하는 과정을 간소화합니다.")])]),t._v(" "),a("h3",{attrs:{id:"예제"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#예제"}},[t._v("#")]),t._v(" 예제")]),t._v(" "),a("p",[t._v("PySpark에서 "),a("code",[t._v("SparkSession")]),t._v("을 생성하는 방법은 다음과 같습니다:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SparkSession\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SparkSession 생성")]),t._v("\nspark "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkSession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder \\\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"example_spark_session"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \\\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("ul",[a("li",[a("code",[t._v("SparkSession.builder")]),t._v(": "),a("code",[t._v("SparkSession")]),t._v(" 생성을 시작합니다.")]),t._v(" "),a("li",[a("code",[t._v('appName("example_spark_session")')]),t._v(": 애플리케이션의 이름을 설정합니다.")]),t._v(" "),a("li",[a("code",[t._v("getOrCreate()")]),t._v(": 기존에 존재하는 "),a("code",[t._v("SparkSession")]),t._v("을 가져오거나 새로 생성합니다.")])]),t._v(" "),a("h2",{attrs:{id:"sparkcontext란"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sparkcontext란"}},[t._v("#")]),t._v(" SparkContext란?")]),t._v(" "),a("p",[a("code",[t._v("SparkContext")]),t._v("는 Spark 기능의 원래 진입점입니다. Spark 클러스터에 연결하고 데이터를 로드하며, Spark의 핵심 기능과 상호작용하는 역할을 합니다.")]),t._v(" "),a("h2",{attrs:{id:"왜-sparkcontext를-사용할까요"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#왜-sparkcontext를-사용할까요"}},[t._v("#")]),t._v(" 왜 SparkContext를 사용할까요?")]),t._v(" "),a("ol",[a("li",[t._v("저수준 작업 지원: 저수준 작업 및 구성을 사용할 수 있는 기능을 제공합니다.")]),t._v(" "),a("li",[t._v("RDD 조작: Resilient Distributed Datasets(RDDs)을 직접 다루기 위해 필수적입니다.")])]),t._v(" "),a("h3",{attrs:{id:"예제-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#예제-2"}},[t._v("#")]),t._v(" 예제:")]),t._v(" "),a("p",[t._v("PySpark에서 "),a("code",[t._v("SparkContext")]),t._v("를 생성하는 방법은 다음과 같습니다:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SparkContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkConf\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Spark 구성 생성")]),t._v("\nconf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkConf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"example_spark_context"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SparkContext 생성")]),t._v("\nsc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("conf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("ul",[a("li",[a("code",[t._v('SparkConf().setAppName("example_spark_context")')]),t._v(": Spark 설정에서 애플리케이션 이름을 설정합니다.")]),t._v(" "),a("li",[a("code",[t._v("SparkContext(conf=conf)")]),t._v(": 주어진 설정을 사용하여 "),a("code",[t._v("SparkContext")]),t._v("를 초기화합니다.")])]),t._v(" "),a("h2",{attrs:{id:"언제-무엇을-사용해야-할까요"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#언제-무엇을-사용해야-할까요"}},[t._v("#")]),t._v(" 언제 무엇을 사용해야 할까요?")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("SparkSession:")]),t._v(" "),a("ul",[a("li",[t._v("DataFrame과 SQL 같은 고수준 API를 사용할 때 사용합니다.")]),t._v(" "),a("li",[t._v("간단하고 통합된 인터페이스 덕분에 대부분의 데이터 처리 작업에 적합합니다.")])])]),t._v(" "),a("li",[a("p",[t._v("SparkContext:")]),t._v(" "),a("ul",[a("li",[t._v("저수준 RDD 작업을 수행할 때 사용합니다.")]),t._v(" "),a("li",[t._v("Spark 실행의 기본 요소를 더 많이 제어하거나 RDD를 직접 조작해야 할 때 필요합니다.")])])])]),t._v(" "),a("h3",{attrs:{id:"예제-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#예제-3"}},[t._v("#")]),t._v(" 예제:")]),t._v(" "),a("p",[a("code",[t._v("SparkSession")]),t._v("과 "),a("code",[t._v("SparkContext")]),t._v("를 함께 사용하는 방법을 살펴보겠습니다:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SparkSession\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SparkSession 생성")]),t._v("\nspark "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkSession"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder \\\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"example_spark_session"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \\\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SparkSession에서 SparkContext 가져오기")]),t._v("\nsc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SparkContext를 사용하여 간단한 RDD 생성")]),t._v("\nrdd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SparkSession을 사용하여 RDD를 DataFrame으로 변환")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDataFrame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# DataFrame 출력")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("ol",[a("li",[a("code",[t._v("SparkSession")]),t._v("을 생성합니다.")]),t._v(" "),a("li",[a("code",[t._v("spark.sparkContext")]),t._v("를 사용해 기본 "),a("code",[t._v("SparkContext")]),t._v("에 접근합니다.")]),t._v(" "),a("li",[t._v("숫자로 구성된 리스트에서 RDD를 생성합니다.")]),t._v(" "),a("li",[t._v("RDD를 DataFrame으로 변환하고, "),a("code",[t._v("show()")]),t._v("를 사용해 출력합니다.")])]),t._v(" "),a("h2",{attrs:{id:"결론"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#결론"}},[t._v("#")]),t._v(" 결론")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("SparkSession")]),t._v(": 사용하기 쉽고 통합된 인터페이스 덕분에 대부분의 데이터 처리 작업에 적합합니다.")]),t._v(" "),a("li",[a("code",[t._v("SparkContext")]),t._v(": 저수준 작업이나 RDD를 직접 다뤄야 할 때 사용합니다.")])])])}),[],!1,null,null,null);a.default=e.exports}}]);